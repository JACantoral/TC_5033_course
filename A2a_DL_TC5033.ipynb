{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "601b2309",
   "metadata": {},
   "source": [
    "# TC 5033\n",
    "## Deep Learning\n",
    "## Fully Connected Deep Neural Networks using PyTorch\n",
    "<br>\n",
    "\n",
    "#### Activity 2a: Implementing a FC for ASL Dataset using PyTorch\n",
    "<br>\n",
    "\n",
    "\n",
    "- Objective\n",
    "\n",
    "    The primary aim of this activity is to transition from using Numpy for network implementation to utilizing PyTorch, a powerful deep learning framework. You will be replicating the work you did for the ASL dataset in Activity 1b, but this time, you'll implement a your multi layer FC model using PyTorch.\n",
    "    \n",
    "- Instructions\n",
    "\n",
    "    Review Previous Work: Begin by reviewing your Numpy-based Fully Connected Network for the ASL dataset from Activity 1b. Note the architecture, hyperparameters, and performance metrics for comparison.\n",
    "\n",
    "    Introduce PyTorch: If you're new to PyTorch, take some time to familiarize yourself with its basic operations and syntax. You can consult the official documentation or follow online tutorials.\n",
    "\n",
    "    Prepare the ASL Dataset: As before, download and preprocess the Kaggle ASL dataset. \n",
    "\n",
    "    Implement the Network: Design your network architecture tailored for the ASL dataset. Pay special attention to PyTorch modules like nn.Linear() and nn.ReLU().\n",
    "\n",
    "    Train the Model: Implement the training loop, making use of PyTorch's autograd to handle backpropagation. Monitor metrics like loss and accuracy as the model trains.\n",
    "\n",
    "    Analyze and Document: In Markdown cells, discuss the architecture choices, any differences in performance between the Numpy and PyTorch implementations, and insights gained from using a deep learning framework like PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183db241",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "#PyTorch stuff\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Solamente para usuarios de Jupyter Themes\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3896ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '/media/pepe/DataUbuntu/Databases/asl_data/'\n",
    "DATA_PATH = '/home/pepe/Documents/github_repos/datasets/asl_data'\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(DATA_PATH, 'sign_mnist_valid.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fa938e",
   "metadata": {},
   "source": [
    "### Always a good idea to explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149b4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf2d1df",
   "metadata": {},
   "source": [
    "### Get training label data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4348519c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(train_df['label'])\n",
    "y_val = np.array(valid_df['label'])\n",
    "del train_df['label']\n",
    "del valid_df['label']\n",
    "x_train = train_df.values.astype(np.float32)\n",
    "x_val = valid_df.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9bed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea87a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7edd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_val_test(x, y, pct=0.5, shuffle=True):\n",
    "    assert x.shape[0] == y.shape[0], 'Number of samples x!= number samples y'\n",
    "    total_samples = x.shape[0]\n",
    "    if shuffle:\n",
    "        idxs = np.arange(x.shape[0])\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        #return x_val, y_val, x_test, y_test\n",
    "#         return x[:total_samples//2, :], y[:total_samples//2], x[total_samples//2:, :], y[total_samples//2:]\n",
    "    return x[:int(total_samples*pct), :], y[:int(total_samples*pct)], x[int(total_samples*(pct)):, :], y[int(total_samples*(pct)):]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb6fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val, y_val, x_test, y_test = split_val_test(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a02137",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986ec106",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65bdf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet=list(string.ascii_lowercase)\n",
    "alphabet.remove('j')\n",
    "alphabet.remove('z')\n",
    "print(len(alphabet))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17874be",
   "metadata": {},
   "source": [
    "### Normalise the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5cce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x_mean, x_std, x_data):\n",
    "    return (x_data - x_mean) / x_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cf6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mean = x_train.mean()\n",
    "x_std = x_train.std()\n",
    "\n",
    "x_train = normalise(x_mean, x_std, x_train)\n",
    "x_val = normalise(x_mean, x_std, x_val)\n",
    "x_test = normalise(x_mean, x_std, x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eef77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.mean(), x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4761728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_number(image):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(image.squeeze(), cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eb103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9216b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = np.random.randint(len(y_val))\n",
    "# print(rnd_idx)\n",
    "# print(y_val[rnd_idx])\n",
    "print(f'La imagen muestreada representa un: {alphabet[y_val[rnd_idx]]}')\n",
    "plot_number(x_val[rnd_idx].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668cfc56",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c833b",
   "metadata": {},
   "source": [
    "$$z^1 = W^1 X + b^1$$\n",
    "\n",
    "$$a^1 = ReLU(z^1) $$\n",
    "\n",
    "$$z^2 = W^2 a^1 + b^2$$\n",
    "\n",
    "$$\\hat{y} = \\frac{e^{z^{2_k}}}{\\sum_j{e^{z_j}}}$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{L}(\\hat{y}^{i}, y^{i}) =  - y^{i}  \\ln(\\hat{y}^{i}) = -\\ln(\\hat{y}^i)$$\n",
    "\n",
    "\n",
    "$$ \\mathcal{J}(w, b) =  \\frac{1}{num\\_samples} \\sum_{i=1}^{num\\_samples}-\\ln(\\hat{y}^{i})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae3ef9",
   "metadata": {},
   "source": [
    "### Create minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780beecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minibatches(mb_size, x, y, shuffle = True):\n",
    "    '''\n",
    "    x  #muestras, 784\n",
    "    y #muestras, 1\n",
    "    '''\n",
    "    assert x.shape[0] == y.shape[0], 'Error en cantidad de muestras'\n",
    "    total_data = x.shape[0]\n",
    "    if shuffle: \n",
    "        idxs = np.arange(total_data)\n",
    "        np.random.shuffle(idxs)\n",
    "        x = x[idxs]\n",
    "        y = y[idxs]\n",
    "        \n",
    "    return ((x[i:i+mb_size], y[i:i+mb_size]) for i in range(0, total_data, mb_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x, y) in enumerate(create_minibatches(128,x_train, y_train)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12273997",
   "metadata": {},
   "source": [
    "### Now the PyTorch part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd1415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor = torch.tensor(x_train.copy())\n",
    "y_train_tensor = torch.tensor(y_train.copy())\n",
    "\n",
    "x_val_tensor = torch.tensor(x_val.copy())\n",
    "y_val_tensor = torch.tensor(y_val.copy())\n",
    "\n",
    "x_test_tensor = torch.tensor(x_test.copy())\n",
    "y_test_tensor = torch.tensor(y_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087285a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c3ba5",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e0f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(model, x, y, mb_size):\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    cost = 0.\n",
    "    model.eval()\n",
    "    model = model.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        for mb, (xi, yi) in enumerate(create_minibatches(mb_size, x, y),1):\n",
    "            xi = xi.to(device=device, dtype = torch.float32)\n",
    "            yi = yi.to(device=device, dtype = torch.long)\n",
    "            scores = model(xi) # mb_size, 10\n",
    "            cost += (F.cross_entropy(scores, yi)).item()\n",
    "            _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
    "            num_correct += (pred == yi.squeeze()).sum() # pred shape (mb_size), yi shape (mb_size, 1)\n",
    "            num_total += pred.size(0)\n",
    "\n",
    "        return cost/mb, float(num_correct)/num_total  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533c2954",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0e44c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, mb_size, epochs=100):\n",
    "    model = model.to(device=device)\n",
    "    train_cost = 0.\n",
    "    val_cost = 0.\n",
    "    for epoch in range(epochs):\n",
    "        train_correct_num  = 0.\n",
    "        train_total = 0.\n",
    "        train_cost_acum = 0\n",
    "        for mb, (xi, yi) in enumerate(create_minibatches(mb_size, x_train_tensor, y_train_tensor), 1):\n",
    "            model.train()\n",
    "            xi = xi.to(device=device, dtype=torch.float32)\n",
    "            yi = yi.to(device=device, dtype=torch.long)\n",
    "            scores = model(xi)\n",
    "            # funcion cost\n",
    "            cost = F.cross_entropy(input= scores, target=yi.squeeze())\n",
    "            optimiser.zero_grad()\n",
    "            cost.backward()\n",
    "            optimiser.step()\n",
    "            \n",
    "            train_correct_num += (torch.argmax(scores, dim=1) == yi.squeeze()).sum()\n",
    "            train_total += scores.size(0)  \n",
    "            \n",
    "            train_cost_acum += cost.item()\n",
    "        \n",
    "        val_cost, val_acc = accuracy(model, x_val_tensor, y_val_tensor, mb_size)\n",
    "        train_acc = float(train_correct_num)/train_total\n",
    "        train_cost = train_cost_acum/mb\n",
    "        if epoch%20 == 0:            \n",
    "            print(f'Epoch:{epoch}, train cost: {train_cost:.6f}, val cost: {val_cost:.6f},'\n",
    "                      f' train acc: {train_acc:.4f}, val acc: {val_acc:4f},'\n",
    "                      f' lr: {optimiser.param_groups[0][\"lr\"]:.6f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b9243",
   "metadata": {},
   "source": [
    "### Model using Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d678e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar modelo\n",
    "# hidden1 = 100 \n",
    "hidden = 200\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "mb_size = 128\n",
    "model1 = nn.Sequential(nn.Linear(in_features=784, out_features=hidden), \n",
    "                       nn.Dropout(),\n",
    "                       nn.ReLU(),\n",
    "#                        nn.Linear(in_features=hidden1, out_features=hidden), nn.ReLU(),\n",
    "                       nn.Linear(in_features=hidden, out_features=24))\n",
    "# optimiser = torch.optim.SGD(model1.parameters(), lr=lr, momentum=0.9, weight_decay=1e-2)\n",
    "optimiser = torch.optim.Adam(model1.parameters(), lr=lr, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimiser, 0.1, epochs=epochs, steps_per_epoch=215)\n",
    "\n",
    "train(model1, optimiser, mb_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1942c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(model1, x_test_tensor, y_test_tensor, mb_size)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa8f9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, model):\n",
    "    x = x.to(device=device, dtype = torch.float32)\n",
    "    scores = model(x) # mb_size, 10\n",
    "    _, pred = scores.max(dim=1) #pred shape (mb_size )\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4edc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_idx = np.random.randint(len(y_test))\n",
    "print(f'La imagen muestreada representa un: {alphabet[y_test[rnd_idx]]}')\n",
    "plot_number(x_test[rnd_idx].reshape(28,28))\n",
    "pred=predict(x_test_tensor[rnd_idx].reshape(1, -1), model1)\n",
    "print(f'el valor predicho {alphabet[pred]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d10e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69ab2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9787c25d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
